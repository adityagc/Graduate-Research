{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group lasso for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the group lasso penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityagc/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Same setup as 'demo_group_lasso_tensorflow', but we implement training and regularization\n",
    "inside the Keras library. See the other demo for details. The most important part\n",
    "of the code is the L21 class (see below), which can be added to any Keras Dense layer.\n",
    "\n",
    "Note that we do not use TensorBoard here, but we simply plot the loss and number of neurons\n",
    "obtained from a callback class using Matplotlib.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import Regularizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class L21(Regularizer):\n",
    "    \"\"\"Regularizer for L21 regularization.\n",
    "    # Arguments\n",
    "        C: Float; L21 regularization factor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C=0.):\n",
    "        self.C = K.cast_to_floatx(C)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        const_coeff = np.sqrt(K.int_shape(x)[1])\n",
    "        return self.C*const_coeff*K.sum(K.sqrt(K.sum(K.square(x), axis=1)))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'C': float(self.l1)}\n",
    "\n",
    "# Utility function to count active neurons in a Keras model with Dense layers\n",
    "def count_neurons(model):\n",
    "    return np.sum([np.sum(np.sum(np.abs(l.get_weights()[0]), axis=1) > 10**-3) \\\n",
    "                          for l in model.layers])\n",
    "\n",
    "# Callback class to save training loss and the number of neurons\n",
    "class TrainHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.neurons = [count_neurons(self.model)]\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.neurons.append(count_neurons(self.model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = np.genfromtxt('../Cleaning/X_train.csv', delimiter=',')\n",
    "X_tst = np.genfromtxt('../Cleaning/X_test.csv', delimiter=',')\n",
    "y_trn = np.genfromtxt('../Cleaning/Y_train.csv', delimiter=',')\n",
    "y_tst = np.genfromtxt('../Cleaning/Y_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the group-lasso penalized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-74d5e7c71589>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-74d5e7c71589>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    model.add(Dense(15, activation='linear', /home/adityagc/Desktop/desk/MS-Research=L21(0.001)))\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Reset session\n",
    "tf.reset_default_graph()\n",
    "K.set_session(tf.Session())\n",
    "\n",
    "# Define the model in Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_trn.shape[1],  activation='relu', kernel_regularizer=L21(0.001)))\n",
    "model.add(Dense(15, activation='linear', /home/adityagc/Desktop/desk/MS-Research=L21(0.001)))\n",
    "model.add(Dense(1, activation='linear', kernel_regularizer=L21(0.001)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Get callbacks\n",
    "history = TrainHistory()\n",
    "\n",
    "# Train using batch gradient descent\n",
    "model.fit(X_trn, y_trn, epochs=2500, shuffle=False, batch_size=X_trn.shape[0], verbose=0, callbacks=[history])\n",
    "\n",
    "# Evaluate on test data\n",
    "y_tst_hat = model.predict(X_tst, batch_size=X_tst.shape[0])\n",
    "print('Final loss on test set: ', mean_squared_error(y_tst, y_tst_hat))\n",
    "\n",
    "# Plot the training loss during training\n",
    "plt.figure()\n",
    "plt.plot(history.losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the active neurons during training\n",
    "plt.figure()\n",
    "plt.plot(history.neurons)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Active neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
