{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got float.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f7ff071ed393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlls_l2l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'KKT conditions verified:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_kkt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f7ff071ed393>\u001b[0m in \u001b[0;36mlls_l2l1\u001b[0;34m(A, b, penalty, groups, max_iter, rtol, verbose)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minitial_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;31m# TODO: better initial guess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 nabla = optimize.newton(phi, initial_guess, dphi, tol=1e-3, maxiter=1e4,\n\u001b[0;32m---> 68\u001b[0;31m                         args=(qp ** 2, eigvals, penalty))\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnabla\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigvects\u001b[0m \u001b[0;34m/\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0meigvals\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnabla\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adityagc/.local/lib/python2.7/site-packages/scipy/optimize/zeros.pyc\u001b[0m in \u001b[0;36mnewton\u001b[0;34m(func, x0, fprime, args, tol, maxiter, fprime2)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfprime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Newton-Rapheson method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mfder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range() integer end argument expected, got float."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg, optimize\n",
    "\n",
    "MAX_ITER = 100\n",
    "\n",
    "def lls_l2l1(A, b, penalty, groups, max_iter=MAX_ITER, rtol=1e-6,\n",
    "             verbose=False):\n",
    "    \"\"\"\n",
    "    Linear least-squares with l2/l1 regularization solver.\n",
    "    Solves problem of the form:\n",
    "               .5 * |Xb - y| + n_samples * penalty * Sum(|b_j|)\n",
    "    where |.| is the l2-norm and b_j is the coefficients of b in the\n",
    "    j-th group. This is commonly known as the `group lasso`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array of shape (n_samples, n_features)\n",
    "        Design Matrix.\n",
    "    b : array of shape (n_samples,)\n",
    "    penalty : float\n",
    "        Amount of penalization to use.\n",
    "    groups : array of shape (n_features,)\n",
    "        Group label. For each column, it indicates\n",
    "        its group apertenance.\n",
    "    rtol : float\n",
    "        Relative tolerance. ensures ||x - x_|| / x_ < rtol,\n",
    "        where x_ is the approximate solution and x is the\n",
    "        true solution.\n",
    "    Returns\n",
    "    -------\n",
    "    x : array\n",
    "        vector of coefficients\n",
    "    References\n",
    "    ----------\n",
    "    \"Efficient Block-coordinate Descent Algorithms for the Group Lasso\",\n",
    "    Qin, Scheninberg, Goldfarb\n",
    "    \"\"\"\n",
    "\n",
    "    # .. local variables ..\n",
    "    A, b, groups, penalty = map(np.asanyarray, (A, b, groups, penalty))\n",
    "    if len(groups) != A.shape[1]:\n",
    "        raise ValueError(\"Incorrect shape for groups\")\n",
    "    x = np.zeros(A.shape[1], dtype=A.dtype)\n",
    "    penalty = penalty * A.shape[0]\n",
    "\n",
    "    # .. precompute ..\n",
    "    H = np.dot(A.T, A)\n",
    "    group_labels = [groups == i for i in np.unique(groups)]\n",
    "    H_groups = [np.dot(A[:, g].T, A[:, g]) for g in group_labels]\n",
    "    eig = [linalg.eigh(H_groups[i]) for i in range(len(group_labels))]\n",
    "    Ab = np.dot(A.T, b)\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        def phi(nabla_, qp2, eigvals, penalty):\n",
    "            return 1 - np.sum( qp2 / ((nabla_ * eigvals + penalty) ** 2))\n",
    "        def dphi(nabla_, alpha, eigvals, penalty):\n",
    "            # .. first derivative of phi ..\n",
    "            return np.sum((2 * alpha * eigvals) / ((penalty + nabla_ * eigvals) ** 3))\n",
    "        for i, g in enumerate(group_labels):\n",
    "            # .. shrinkage operator ..\n",
    "            eigvals, eigvects = eig[i]\n",
    "            x_i = x.copy()\n",
    "            x_i[g] = 0.\n",
    "            A_residual = np.dot(H[g], x_i) - Ab[g]\n",
    "            qp = np.dot(eigvects.T, A_residual)\n",
    "            if penalty < linalg.norm(A_residual, 2):\n",
    "                initial_guess = 0. # TODO: better initial guess\n",
    "                nabla = optimize.newton(phi, initial_guess, dphi, tol=1e-3, maxiter=1e4,\n",
    "                        args=(qp ** 2, eigvals, penalty))\n",
    "                x[g] = - nabla * np.dot(eigvects /  (eigvals * nabla + penalty), qp)\n",
    "            else:\n",
    "                x[g] = 0.\n",
    "\n",
    "        # .. dual gap ..\n",
    "        if n_iter % 3:\n",
    "            residual = np.dot(A, x) - b\n",
    "            group_norm = penalty * np.sum([linalg.norm(x[g], 2)\n",
    "                         for i, g in enumerate(group_labels)])\n",
    "            norm_Anu = [linalg.norm(np.dot(H[g], x) - Ab[g]) \\\n",
    "                       for g in group_labels]\n",
    "            if np.any(norm_Anu > penalty):\n",
    "                nnu = residual * np.min(penalty / norm_Anu)\n",
    "            else:\n",
    "                nnu = residual\n",
    "            primal_obj =  .5 * np.dot(residual, residual) + group_norm\n",
    "            dual_obj   = -.5 * np.dot(nnu, nnu) - np.dot(nnu, b)\n",
    "            dual_gap = primal_obj - dual_obj\n",
    "            if verbose:\n",
    "                print 'Relative error: %s' % (dual_gap / dual_obj)\n",
    "            if np.abs(dual_gap / dual_obj) < rtol:\n",
    "                break\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def check_kkt(A, b, x, penalty, groups):\n",
    "    \"\"\"Check KKT conditions for the group lasso\n",
    "    Returns True if conditions are satisfied, False otherwise\n",
    "    \"\"\"\n",
    "    group_labels = [groups == i for i in np.unique(groups)]\n",
    "    penalty = penalty * A.shape[0]\n",
    "    z = np.dot(A.T, np.dot(A, x) - b)\n",
    "    safety_net = 1e-1 # sort of tolerance\n",
    "    for g in group_labels:\n",
    "        if linalg.norm(x[g]) == 0:\n",
    "            if not linalg.norm(z[g]) < penalty + safety_net:\n",
    "                return False\n",
    "        else:\n",
    "            w = - penalty * x[g] / linalg.norm(x[g], 2)\n",
    "            if not np.allclose(z[g], w, safety_net):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "penalty = .1\n",
    "groups = np.r_[[0, 0], np.arange(X.shape[1] - 2)]\n",
    "coefs = lls_l2l1(X, y, penalty, groups, verbose=True)\n",
    "print 'KKT conditions verified:', check_kkt(X, y, coefs, penalty, groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
